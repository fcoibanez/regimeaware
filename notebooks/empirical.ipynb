{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical exercise should focus on how the sector and factor tilting works when a crisis comes, better diversification provided, consistent risk factor contributions, and greater resilience to economic shocks\n",
    "\n",
    "I should present two applications:\n",
    "1. single name \n",
    "2. sector rotation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_58076\\514321698.py:13: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  rebalance_dts = pd.date_range(start=cfg.bt_start_dt, end=cfg.bt_end_dt, freq=cfg.rebalance_freq)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_58076\\514321698.py:31: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  rf = rf.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_58076\\514321698.py:33: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  rt = rt.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "import cvxpy as cp\n",
    "from tqdm.notebook import tqdm\n",
    "from regimeaware.routines import cfg\n",
    "from itertools import product\n",
    "from regimeaware.core import utils\n",
    "\n",
    "rebalance_dts = pd.date_range(start=cfg.bt_start_dt, end=cfg.bt_end_dt, freq=cfg.rebalance_freq)\n",
    "\n",
    "# CRSP & COMPUSTAT data set loading\n",
    "gics_mapping = pd.read_pickle(f'{cfg.data_fldr}/gics_mapping.pkl')\n",
    "crsp = pd.read_pickle(f'{cfg.data_fldr}/crsp_daily.pkl')\n",
    "crsp['mktcap'] = crsp['shrout'].mul(crsp['prc']).abs().replace(0, np.nan)\n",
    "crsp['dollar_vol'] = crsp['prc'].mul(crsp['vol'])\n",
    "crsp['industry'] = crsp['siccd'].apply(utils.assign_industry)\n",
    "crsp = crsp.join(gics_mapping['sector'], how='left', on='permno')\n",
    "\n",
    "# Load cached factor estimates\n",
    "factor_covars = pd.read_pickle(f'{cfg.data_fldr}/moments/factor_covars.pkl')\n",
    "factor_means = pd.read_pickle(f'{cfg.data_fldr}/moments/factor_means.pkl')\n",
    "factor_loadings = pd.read_pickle(f'{cfg.data_fldr}/exposures/forecasted_betas.pkl')\n",
    "factor_variance = pd.read_pickle(f'{cfg.data_fldr}/exposures/var.pkl')\n",
    "\n",
    "# Monthly performance time series\n",
    "rf = pd.read_pickle(f'{cfg.data_fldr}/ff_daily.pkl')['rf']\n",
    "rf = rf.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
    "rt = pd.pivot_table(crsp, index='date', columns='permno', values='ret')\n",
    "rt = rt.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
    "rt = rt.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\underset{w}{\\text{argmin}} & & \\gamma \\left( w^{T} F^{T} \\Sigma_{f} F w + w^{T} E w \\right) - w^{T} \\mu_{f} \\\\\n",
    "& \\text{s.t.} & & (w - b)^{T} \\Sigma (w - b) \\leq \\bar{\\sigma}^{2} \\\\\n",
    "& & & \\sum_{i=1}^{N} w_i = 1 \\\\\n",
    "& & &  w_i \\geq 0 \\; ; \\; \\forall \\; i =1, \\ldots, N \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk aversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average betas per sector, this should reduce F to a 10-by-n, but this only works if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_bm = {}\n",
    "\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "for g, dt in product(cfg.gamma_iter, rebalance_dts):\n",
    "    print(f'Gamma: {g}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap', 'sector']].xs(as_of_dt)).dropna().index\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "\n",
    "    indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    I = pd.get_dummies(indu_t).astype(int)\n",
    "    indu_labels = I.columns\n",
    "    I = I.values\n",
    "\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "    b = b.values.reshape(-1, 1)\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    m, n = F.shape\n",
    "    w = cp.Variable((n, 1))\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ (w - b))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == F @ (w - b),\n",
    "        w >= 0\n",
    "    ]\n",
    "\n",
    "    gamma.value = g\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return - gamma * port_risk), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(g, dt)] = pd.Series(w.value.flatten(), index=tradable_ids)\n",
    "    bm_indu_wts = pd.Series((b.T @ I).flatten(), indu_labels)\n",
    "    bt_indu_wts = pd.Series((w.value.T @ I).flatten(), indu_labels)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['gamma', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for g in cfg.gamma_iter:\n",
    "    wt = wts.xs(g)\n",
    "    collect_bt[g] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'Gamma: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Stats/plots\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())\n",
    "\n",
    "df.div(df.cummax()).sub(1).plot()\n",
    "\n",
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "print('Average number of stocks', wts.mask(zero_flags).count(axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anchor the risk aversion parameter to TEV, enough to generate around 6%\n",
    "\n",
    "## TEV cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_bm = {}\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "for dt, tev in product(rebalance_dts, cfg.tev_budget_iter):\n",
    "    print(f'TEV: {tev}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap', 'sector']].xs(as_of_dt)).dropna().index\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "    b = b.values.reshape(-1, 1)\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    m, n = F.shape\n",
    "    w = cp.Variable((n, 1))\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ (w - b))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == F @ (w - b),\n",
    "        w >= 0,\n",
    "        port_risk <= (tev ** 2) / 12\n",
    "    ]\n",
    "\n",
    "    gamma.value = g\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(tev, dt)] = pd.Series(w.value.flatten(), index=tradable_ids)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['tev', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for tev in cfg.tev_budget_iter:\n",
    "    wt = wts.xs(tev)\n",
    "    collect_bt[tev] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'TEV: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())\n",
    "\n",
    "df.div(df.cummax()).sub(1).plot()\n",
    "\n",
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "print('Average number of stocks', wts.mask(zero_flags).count(axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector Rotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\text{diag} \\left( c\\right) M \\left( \\text{diag} \\left (c^{T} M \\right) \\right)^{-1}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEV: 0.02, Date: 2013 Oct       \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\cvxpy\\problems\\problem.py:1403: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEV: 0.02, Date: 2022 Dec       \r"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0.01",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:1698\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:1722\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Float64HashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0.01",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m collect_bt \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tev \u001b[38;5;129;01min\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mtev_budget_iter:\n\u001b[1;32m---> 63\u001b[0m     wt \u001b[38;5;241m=\u001b[39m wts\u001b[38;5;241m.\u001b[39mxs(tev)\n\u001b[0;32m     64\u001b[0m     collect_bt[tev] \u001b[38;5;241m=\u001b[39m wt\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmul(rt)\u001b[38;5;241m.\u001b[39mdropna(how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# Backtests\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\pandas\\core\\generic.py:4287\u001b[0m, in \u001b[0;36mNDFrame.xs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   4284\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m   4286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, MultiIndex):\n\u001b[1;32m-> 4287\u001b[0m     loc, new_index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39m_get_loc_level(key, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   4288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m drop_level:\n\u001b[0;32m   4289\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_integer(loc):\n\u001b[0;32m   4290\u001b[0m             \u001b[38;5;66;03m# Slice index must be an integer or None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3290\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_level\u001b[1;34m(self, key, level)\u001b[0m\n\u001b[0;32m   3288\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m indexer, maybe_mi_droplevels(indexer, ilevels)\n\u001b[0;32m   3289\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3290\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_level_indexer(key, level\u001b[38;5;241m=\u001b[39mlevel)\n\u001b[0;32m   3291\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3292\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m   3293\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels[level]\u001b[38;5;241m.\u001b[39m_supports_partial_string_indexing\n\u001b[0;32m   3294\u001b[0m     ):\n\u001b[0;32m   3295\u001b[0m         \u001b[38;5;66;03m# check to see if we did an exact lookup vs sliced\u001b[39;00m\n\u001b[0;32m   3296\u001b[0m         check \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlevels[level]\u001b[38;5;241m.\u001b[39mget_loc(key)\n",
      "File \u001b[1;32mc:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:3391\u001b[0m, in \u001b[0;36mMultiIndex._get_level_indexer\u001b[1;34m(self, key, level, indexer)\u001b[0m\n\u001b[0;32m   3388\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(i, j, step)\n\u001b[0;32m   3390\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3391\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_loc_single_level_index(level_index, key)\n\u001b[0;32m   3393\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lexsort_depth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   3394\u001b[0m         \u001b[38;5;66;03m# Desired level is not sorted\u001b[39;00m\n\u001b[0;32m   3395\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mslice\u001b[39m):\n\u001b[0;32m   3396\u001b[0m             \u001b[38;5;66;03m# test_get_loc_partial_timestamp_multiindex\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\pandas\\core\\indexes\\multi.py:2980\u001b[0m, in \u001b[0;36mMultiIndex._get_loc_single_level_index\u001b[1;34m(self, level_index, key)\u001b[0m\n\u001b[0;32m   2978\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2979\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m level_index\u001b[38;5;241m.\u001b[39mget_loc(key)\n",
      "File \u001b[1;32mc:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3807\u001b[0m     ):\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 0.01"
     ]
    }
   ],
   "source": [
    "collect_wt = {}\n",
    "collect_indu_wt = {}\n",
    "collect_bm = {}\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "\n",
    "for dt, tev in product(rebalance_dts, cfg.tev_budget_iter):\n",
    "    print(f'TEV: {tev}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap', 'sector']].xs(as_of_dt)).dropna().index\n",
    "    indu_t = crsp['sector'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    m, n = F.shape\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "    M = pd.get_dummies(indu_t).astype(int)\n",
    "    indu_labels = M.columns\n",
    "    M = M.values\n",
    "    c = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids).values.reshape(-1, 1)  # Stock market cap\n",
    "    W = (np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten())))\n",
    "    B = F @ W  # Industry betas\n",
    "    wb = np.divide(c.T @ M, c.T @ np.ones(n)).T\n",
    "    \n",
    "    # Benchmark weights\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    k = M.shape[1]  # Number of industries\n",
    "    w = cp.Variable((k, 1))  # We are allocating across industries now\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ W @ (w - wb))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == B @ (w - wb),\n",
    "        w >= 0,\n",
    "        port_risk <= (tev ** 2) / 12\n",
    "    ]\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(tev, dt)] = pd.Series((W @ w.value).flatten(), index=tradable_ids)\n",
    "    collect_indu_wt[(tev, dt)] = pd.Series(w.value.flatten(), index=indu_labels)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['tev', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for tev in cfg.tev_budget_iter:\n",
    "    wt = wts.xs(tev)\n",
    "    collect_bt[tev] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'TEV: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "df.plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())\n",
    "\n",
    "df.div(df.cummax()).sub(1).plot()\n",
    "\n",
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "print('Average number of stocks', wts.mask(zero_flags).count(axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_indu_wt = {}\n",
    "collect_bm = {}\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "\n",
    "for dt, tev, g in product(rebalance_dts, cfg.tev_budget_iter, cfg.gamma_iter):\n",
    "    print(f'TEV: {tev}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap', 'sector']].xs(as_of_dt)).dropna().index\n",
    "    indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    m, n = F.shape\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "    M = pd.get_dummies(indu_t).astype(int)\n",
    "    indu_labels = M.columns\n",
    "    M = M.values\n",
    "    c = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids).values.reshape(-1, 1)  # Stock market cap\n",
    "    W = (np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten())))\n",
    "    B = F @ W  # Industry betas\n",
    "    wb = np.divide(c.T @ M, c.T @ np.ones(n)).T\n",
    "    \n",
    "    # Benchmark weights\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    k = M.shape[1]  # Number of industries\n",
    "    w = cp.Variable((k, 1))  # We are allocating across industries now\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ W @ (w - wb))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == B @ (w - wb),\n",
    "        w >= 0,\n",
    "        port_risk <= (tev ** 2) / 12\n",
    "    ]\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(tev, dt)] = pd.Series((W @ w.value).flatten(), index=tradable_ids)\n",
    "    collect_indu_wt[(tev, dt)] = pd.Series(w.value.flatten(), index=indu_labels)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['tev', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for tev in cfg.tev_budget_iter:\n",
    "    wt = wts.xs(tev)\n",
    "    collect_bt[tev] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'TEV: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "df.plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())\n",
    "\n",
    "df.div(df.cummax()).sub(1).plot()\n",
    "\n",
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "print('Average number of stocks', wts.mask(zero_flags).count(axis=1).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
