{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical exercise should focus on how the sector and factor tilting works when a crisis comes, better diversification provided, consistent risk factor contributions, and greater resilience to economic shocks\n",
    "\n",
    "I should present two applications:\n",
    "1. single name \n",
    "2. sector rotation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "import cvxpy as cp\n",
    "from tqdm.notebook import tqdm\n",
    "from regimeaware.routines import cfg\n",
    "from itertools import product\n",
    "from scipy.stats import entropy\n",
    "from regimeaware.core import utils\n",
    "\n",
    "rebalance_dts = pd.date_range(start=cfg.bt_start_dt, end=cfg.bt_end_dt, freq=cfg.rebalance_freq)\n",
    "\n",
    "# CRSP data set loading\n",
    "crsp = pd.read_pickle(f'{cfg.data_fldr}/crsp_daily.pkl')\n",
    "crsp['mktcap'] = crsp['shrout'].mul(crsp['prc']).abs().replace(0, np.nan)\n",
    "crsp['dollar_vol'] = crsp['prc'].mul(crsp['vol'])\n",
    "crsp['industry'] = crsp['siccd'].apply(utils.assign_industry)\n",
    "\n",
    "# Load cached factor estimates\n",
    "factor_covars = pd.read_pickle(f'{cfg.data_fldr}/moments/factor_covars.pkl')\n",
    "factor_means = pd.read_pickle(f'{cfg.data_fldr}/moments/factor_means.pkl')\n",
    "factor_loadings = pd.read_pickle(f'{cfg.data_fldr}/exposures/forecasted_betas.pkl')\n",
    "factor_variance = pd.read_pickle(f'{cfg.data_fldr}/exposures/var.pkl')\n",
    "\n",
    "# Monthly performance time series\n",
    "rf = pd.read_pickle(f'{cfg.data_fldr}/ff_daily.pkl')['rf']\n",
    "rf = rf.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
    "rt = pd.pivot_table(crsp, index='date', columns='permno', values='ret')\n",
    "rt = rt.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
    "rt = rt.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\underset{w}{\\text{argmin}} & & \\gamma \\left( w^{T} F^{T} \\Sigma_{f} F w + w^{T} E w \\right) - w^{T} \\mu_{f} \\\\\n",
    "& \\text{s.t.} & & (w - b)^{T} \\Sigma (w - b) \\leq \\bar{\\sigma}^{2} \\\\\n",
    "& & & \\sum_{i=1}^{N} w_i = 1 \\\\\n",
    "& & &  w_i \\geq 0 \\; ; \\; \\forall \\; i =1, \\ldots, N \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "I = pd.get_dummies(indu_t).astype(int)\n",
    "indu_labels = I.columns\n",
    "I = I.values\n",
    "b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "b = np.divide(b, b.sum())\n",
    "b = b.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk aversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 10)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3359 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3359 is different from 1)"
     ]
    }
   ],
   "source": [
    "b @ I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3359)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3359, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F @ b).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Agriculture       0.000536\n",
       "Construction      0.003934\n",
       "Finance           0.159508\n",
       "Manufacturing     0.482171\n",
       "Mining            0.057725\n",
       "Retail            0.078748\n",
       "Services          0.089944\n",
       "Transportation    0.070627\n",
       "Utilities         0.046219\n",
       "Wholesale         0.010587\n",
       "dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series((b.T @ I).flatten(), index=indu_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(F @ I).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3359 is different from 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43m(\u001b[49m\u001b[43mF\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mI\u001b[49m\n",
      "\u001b[1;31mValueError\u001b[0m: matmul: Input operand 1 has a mismatch in its core dimension 0, with gufunc signature (n?,k),(k,m?)->(n?,m?) (size 3359 is different from 1)"
     ]
    }
   ],
   "source": [
    "(F @ b) @ I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average betas per sector, this should reduce F to a 10-by-n, but this only works if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gamma: 10, Date: 2008 Nov       \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m Sigma_f_const \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((m, m))\n\u001b[0;32m     35\u001b[0m Sigma_f_const[\u001b[38;5;241m1\u001b[39m:, \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m=\u001b[39m Sigma_f\n\u001b[1;32m---> 37\u001b[0m port_risk \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mquad_form(f, Sigma_f_const) \u001b[38;5;241m+\u001b[39m cp\u001b[38;5;241m.\u001b[39msum_squares(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mE\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m@\u001b[39m (w \u001b[38;5;241m-\u001b[39m b))\n\u001b[0;32m     38\u001b[0m port_return \u001b[38;5;241m=\u001b[39m mu_f_const\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m f\n\u001b[0;32m     40\u001b[0m constraints \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     41\u001b[0m     cp\u001b[38;5;241m.\u001b[39msum(w) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     42\u001b[0m     f \u001b[38;5;241m==\u001b[39m F \u001b[38;5;241m@\u001b[39m (w \u001b[38;5;241m-\u001b[39m b),\n\u001b[0;32m     43\u001b[0m     w \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     44\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "collect_wt = {}\n",
    "collect_bm = {}\n",
    "\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "for g, dt in product(cfg.gamma_iter, rebalance_dts):\n",
    "    print(f'Gamma: {g}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "\n",
    "    indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    I = pd.get_dummies(indu_t).astype(int)\n",
    "    indu_labels = I.columns\n",
    "    I = I.values\n",
    "\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "    b = b.values.reshape(-1, 1)\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    m, n = F.shape\n",
    "    w = cp.Variable((n, 1))\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ (w - b))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == F @ (w - b),\n",
    "        w >= 0\n",
    "    ]\n",
    "\n",
    "    gamma.value = g\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return - gamma * port_risk), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(g, dt)] = pd.Series(w.value.flatten(), index=tradable_ids)\n",
    "    bm_indu_wts = pd.Series((b.T @ I).flatten(), indu_labels)\n",
    "    bt_indu_wts = pd.Series((w.value.T @ I).flatten(), indu_labels)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['gamma', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for g in cfg.gamma_iter:\n",
    "    wt = wts.xs(g)\n",
    "    collect_bt[g] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'Gamma: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Stats/plots\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "wts.mask(zero_flags).count(axis=1).groupby('gamma').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anchor the risk aversion parameter to TEV, enough to generate around 6%\n",
    "\n",
    "## TEV cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_bm = {}\n",
    "tev_to_test = np.arange(start=0.01, stop=.08, step=.01)\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "for dt, tev in product(rebalance_dts, tev_to_test):\n",
    "    print(f'TEV: {tev}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "    b = b.values.reshape(-1, 1)\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    m, n = F.shape\n",
    "    w = cp.Variable((n, 1))\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ (w - b))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == F @ (w - b),\n",
    "        w >= 0,\n",
    "        port_risk <= (tev ** 2) / 12\n",
    "    ]\n",
    "\n",
    "    gamma.value = g\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(tev, dt)] = pd.Series(w.value.flatten(), index=tradable_ids)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['tev', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for tev in tev_to_test:\n",
    "    wt = wts.xs(tev)\n",
    "    collect_bt[tev] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'TEV: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "dt = rebalance_dts[0]\n",
    "\n",
    "as_of_dt = crsp_dts.asof(dt)\n",
    "loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "F = loadings_t.reindex(tradable_ids).values.T\n",
    "E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "I = pd.get_dummies(indu_t).astype(int)\n",
    "indu_labels = I.columns\n",
    "I = I.values\n",
    "b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "b = np.divide(b, b.sum())\n",
    "b = b.values.reshape(-1, 1)\n",
    "n = F.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  10.,   46.,  745., 1611.,  140.,  263.,  640.,  170.,  121.,\n",
       "         176.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((n, 1)).T @ I  # Number of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.43325270e+06, 2.79393807e+07, 2.01078484e+09, 4.23774386e+09,\n",
       "        2.28087657e+08, 7.26791120e+08, 9.37928980e+08, 6.26215711e+08,\n",
       "        2.86926829e+08, 1.13410932e+08]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.T @ I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3922, 10)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      0.   ,       0.   ,       0.   , ...,       0.   ,\n",
       "          19046.441,       0.   ],\n",
       "       [      0.   ,       0.   ,   96891.9  , ...,       0.   ,\n",
       "              0.   ,       0.   ],\n",
       "       [      0.   ,       0.   ,       0.   , ...,       0.   ,\n",
       "              0.   ,       0.   ],\n",
       "       ...,\n",
       "       [      0.   ,       0.   ,   39609.3  , ...,       0.   ,\n",
       "              0.   ,       0.   ],\n",
       "       [      0.   ,       0.   ,       0.   , ...,       0.   ,\n",
       "              0.   ,       0.   ],\n",
       "       [      0.   ,       0.   , 1121541.45 , ...,       0.   ,\n",
       "              0.   ,       0.   ]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(c.flatten()) @ I  # mcap casted onto the mapping matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.43325270e+06, 2.79393807e+07, 2.01078484e+09, 4.23774386e+09,\n",
       "        2.28087657e+08, 7.26791120e+08, 9.37928980e+08, 6.26215711e+08,\n",
       "        2.86926829e+08, 1.13410932e+08]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((n, 1)).T  @ np.diag(c.flatten()) @ I  # Total mcap by industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "indu_size = np.ones((n, 1)).T  @ np.diag(c.flatten()) @ I\n",
    "flat_size = np.diag(c.flatten()) @ I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3922, 10)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_size.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 6.63808298e-05, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 4.81861102e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       ...,\n",
       "       [0.00000000e+00, 0.00000000e+00, 1.96984278e-05, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 5.57763032e-04, ...,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_size @ np.linalg.inv(np.diag(indu_size.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "1    1.0\n",
       "2    1.0\n",
       "3    1.0\n",
       "4    1.0\n",
       "5    1.0\n",
       "6    1.0\n",
       "7    1.0\n",
       "8    1.0\n",
       "9    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(flat_size @ np.linalg.inv(np.diag(indu_size.flatten()))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Agriculture         10\n",
       "Construction        46\n",
       "Finance            745\n",
       "Manufacturing     1611\n",
       "Mining             140\n",
       "Retail             263\n",
       "Services           640\n",
       "Transportation     170\n",
       "Utilities          121\n",
       "Wholesale          176\n",
       "Name: industry, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indu_t.groupby(indu_t).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3922)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_bm = {}\n",
    "tev_to_test = np.arange(start=0.01, stop=.08, step=.01)\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "for dt, tev in product(rebalance_dts, tev_to_test):\n",
    "    print(f'TEV: {tev}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "    indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "    I = pd.get_dummies(indu_t).astype(int)\n",
    "    indu_labels = I.columns\n",
    "    I = I.values\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    b = b.values.reshape(-1, 1)\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    m, n = F.shape\n",
    "    w = cp.Variable((n, 1))\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ (w - b))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == F @ (w - b),\n",
    "        w >= 0,\n",
    "        port_risk <= (tev ** 2) / 12\n",
    "    ]\n",
    "\n",
    "    gamma.value = g\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(tev, dt)] = pd.Series(w.value.flatten(), index=tradable_ids)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['tev', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for tev in tev_to_test:\n",
    "    wt = wts.xs(tev)\n",
    "    collect_bt[tev] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'TEV: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "wts.mask(zero_flags).count(axis=1).groupby('gamma').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 / (.06 / np.sqrt(12))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
