{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The empirical exercise should focus on how the sector and factor tilting works when a crisis comes, better diversification provided, consistent risk factor contributions, and greater resilience to economic shocks\n",
    "\n",
    "I should present two applications:\n",
    "1. single name \n",
    "2. sector rotation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_15108\\2464336238.py:13: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  rebalance_dts = pd.date_range(start=cfg.bt_start_dt, end=cfg.bt_end_dt, freq=cfg.rebalance_freq)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_15108\\2464336238.py:29: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  rf = rf.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
      "C:\\Users\\franc\\AppData\\Local\\Temp\\ipykernel_15108\\2464336238.py:31: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  rt = rt.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick\n",
    "import cvxpy as cp\n",
    "from tqdm.notebook import tqdm\n",
    "from regimeaware.routines import cfg\n",
    "from itertools import product\n",
    "from scipy.stats import entropy\n",
    "from regimeaware.core import utils\n",
    "\n",
    "rebalance_dts = pd.date_range(start=cfg.bt_start_dt, end=cfg.bt_end_dt, freq=cfg.rebalance_freq)\n",
    "\n",
    "# CRSP data set loading\n",
    "crsp = pd.read_pickle(f'{cfg.data_fldr}/crsp_daily.pkl')\n",
    "crsp['mktcap'] = crsp['shrout'].mul(crsp['prc']).abs().replace(0, np.nan)\n",
    "crsp['dollar_vol'] = crsp['prc'].mul(crsp['vol'])\n",
    "crsp['industry'] = crsp['siccd'].apply(utils.assign_industry)\n",
    "\n",
    "# Load cached factor estimates\n",
    "factor_covars = pd.read_pickle(f'{cfg.data_fldr}/moments/factor_covars.pkl')\n",
    "factor_means = pd.read_pickle(f'{cfg.data_fldr}/moments/factor_means.pkl')\n",
    "factor_loadings = pd.read_pickle(f'{cfg.data_fldr}/exposures/forecasted_betas.pkl')\n",
    "factor_variance = pd.read_pickle(f'{cfg.data_fldr}/exposures/var.pkl')\n",
    "\n",
    "# Monthly performance time series\n",
    "rf = pd.read_pickle(f'{cfg.data_fldr}/ff_daily.pkl')['rf']\n",
    "rf = rf.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
    "rt = pd.pivot_table(crsp, index='date', columns='permno', values='ret')\n",
    "rt = rt.add(1).groupby(pd.Grouper(freq=cfg.rebalance_freq)).prod().sub(1)\n",
    "rt = rt.replace(0, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\underset{w}{\\text{argmin}} & & \\gamma \\left( w^{T} F^{T} \\Sigma_{f} F w + w^{T} E w \\right) - w^{T} \\mu_{f} \\\\\n",
    "& \\text{s.t.} & & (w - b)^{T} \\Sigma (w - b) \\leq \\bar{\\sigma}^{2} \\\\\n",
    "& & & \\sum_{i=1}^{N} w_i = 1 \\\\\n",
    "& & &  w_i \\geq 0 \\; ; \\; \\forall \\; i =1, \\ldots, N \\\\\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk aversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "average betas per sector, this should reduce F to a 10-by-n, but this only works if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_bm = {}\n",
    "\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "for g, dt in product(cfg.gamma_iter, rebalance_dts):\n",
    "    print(f'Gamma: {g}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "\n",
    "    indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    I = pd.get_dummies(indu_t).astype(int)\n",
    "    indu_labels = I.columns\n",
    "    I = I.values\n",
    "\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "    b = b.values.reshape(-1, 1)\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    m, n = F.shape\n",
    "    w = cp.Variable((n, 1))\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ (w - b))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == F @ (w - b),\n",
    "        w >= 0\n",
    "    ]\n",
    "\n",
    "    gamma.value = g\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return - gamma * port_risk), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(g, dt)] = pd.Series(w.value.flatten(), index=tradable_ids)\n",
    "    bm_indu_wts = pd.Series((b.T @ I).flatten(), indu_labels)\n",
    "    bt_indu_wts = pd.Series((w.value.T @ I).flatten(), indu_labels)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['gamma', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for g in cfg.gamma_iter:\n",
    "    wt = wts.xs(g)\n",
    "    collect_bt[g] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'Gamma: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Stats/plots\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())\n",
    "\n",
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "print('Avrage number of stocks', wts.mask(zero_flags).count(axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anchor the risk aversion parameter to TEV, enough to generate around 6%\n",
    "\n",
    "## TEV cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_bm = {}\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "for dt, tev in product(rebalance_dts, cfg.tev_budget_iter):\n",
    "    print(f'TEV: {tev}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "    b = b.values.reshape(-1, 1)\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    m, n = F.shape\n",
    "    w = cp.Variable((n, 1))\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ (w - b))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == F @ (w - b),\n",
    "        w >= 0,\n",
    "        port_risk <= (tev ** 2) / 12\n",
    "    ]\n",
    "\n",
    "    gamma.value = g\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(tev, dt)] = pd.Series(w.value.flatten(), index=tradable_ids)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['tev', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for tev in tev_to_test:\n",
    "    wt = wts.xs(tev)\n",
    "    collect_bt[tev] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'TEV: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())\n",
    "\n",
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "print('Avrage number of stocks', wts.mask(zero_flags).count(axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sector Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "dt = rebalance_dts[0]\n",
    "\n",
    "as_of_dt = crsp_dts.asof(dt)\n",
    "loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "F = loadings_t.reindex(tradable_ids).values.T\n",
    "E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "M = pd.get_dummies(indu_t).astype(int)  # Industry mapping matrix\n",
    "indu_labels = M.columns\n",
    "M = M.values\n",
    "b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "b = np.divide(b, b.sum())\n",
    "b = b.values.reshape(-1, 1)\n",
    "n = F.shape[1]\n",
    "\n",
    "print(M)  # Industry mapping matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((n, 1)).T @ M  # Number of stocks in a given industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids).values.reshape(-1, 1)  # Stock market cap\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.T @ M  # Industry size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.T @ np.ones(n)  # Total market cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.divide(c.T @ M, c.T @ np.ones(n))  # Industry market cap weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.diag(c.flatten()) @ M  # mcap casted onto the mapping matrix\n",
    "print(C)\n",
    "print(C.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones((n, 1)).T  @ C  # Total mcap by industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "\\text{diag} \\left( c\\right) M \\left( \\text{diag} \\left (c^{T} M \\right) \\right)^{-1}\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten()))\n",
    "# Each column add up to one (weights within that industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten()))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = F @ (np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten())))  # Industry betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(B, columns=indu_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb = np.divide(c.T @ M, c.T @ np.ones(n)).T\n",
    "wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B @ wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_f_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, n = F.shape\n",
    "Sigma_f_const = np.zeros((m, m))\n",
    "Sigma_f_const[1:, 1:] = Sigma_f\n",
    "Sigma_f_const.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(E).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten()))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need a vector of asset weight, starting from the industry weights\n",
    "W = (np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten()))) \n",
    "W @ wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(E) @ W @ (wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids).values.reshape(-1, 1)  # Stock market cap\n",
    "W = (np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten())))\n",
    "B = F @ W  # Industry betas\n",
    "wb = np.divide(c.T @ M, c.T @ np.ones(n)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(w.value.flatten(), index=indu_labels).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(wb.flatten(), index=indu_labels).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(W @ w.value).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_wt = {}\n",
    "collect_indu_wt = {}\n",
    "collect_bm = {}\n",
    "crsp_dts = crsp.index.get_level_values('date').unique()\n",
    "\n",
    "for dt, tev in product(rebalance_dts, [.06]):\n",
    "    print(f'TEV: {tev}, Date: {dt.strftime(\"%Y %b\")}', end='       \\r')\n",
    "    as_of_dt = crsp_dts.asof(dt)\n",
    "    loadings_t = utils.unpack_betas(factor_loadings.xs(dt))\n",
    "    tradable_ids = loadings_t.join(crsp[['ret', 'mktcap']].xs(as_of_dt)).dropna().index\n",
    "    indu_t = crsp['industry'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    mu_f = factor_means.xs(dt)[cfg.factor_set].values.reshape(-1, 1)\n",
    "    mu_f_const = np.concatenate([np.array([[1]]), mu_f], axis=0)  # Adding back the constant\n",
    "    Sigma_f = factor_covars.xs(dt).loc[cfg.factor_set, cfg.factor_set].values\n",
    "    F = loadings_t.reindex(tradable_ids).values.T\n",
    "    m, n = F.shape\n",
    "    E = np.diag(factor_variance.xs(dt).reindex(tradable_ids))\n",
    "    M = pd.get_dummies(indu_t).astype(int)\n",
    "    indu_labels = M.columns\n",
    "    M = M.values\n",
    "    c = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids).values.reshape(-1, 1)  # Stock market cap\n",
    "    W = (np.diag(c.flatten()) @ M @ np.linalg.inv(np.diag((c.T @ M).flatten())))\n",
    "    B = F @ W  # Industry betas\n",
    "    wb = np.divide(c.T @ M, c.T @ np.ones(n)).T\n",
    "    \n",
    "    # Benchmark weights\n",
    "    b = crsp['mktcap'].xs(as_of_dt).reindex(tradable_ids)\n",
    "    b = np.divide(b, b.sum())\n",
    "    collect_bm[dt] = b.copy()\n",
    "\n",
    "    # Optimization problem\n",
    "    tev_budget = cp.Parameter(nonneg=True)\n",
    "    gamma = cp.Parameter(nonneg=True)\n",
    "\n",
    "    k = M.shape[1]  # Number of industries\n",
    "    w = cp.Variable((k, 1))  # We are allocating across industries now\n",
    "    f = cp.Variable((m, 1))\n",
    "\n",
    "    Sigma_f_const = np.zeros((m, m))\n",
    "    Sigma_f_const[1:, 1:] = Sigma_f\n",
    "\n",
    "    port_risk = cp.quad_form(f, Sigma_f_const) + cp.sum_squares(np.sqrt(E) @ W @ (w - wb))\n",
    "    port_return = mu_f_const.T @ f\n",
    "\n",
    "    constraints = [\n",
    "        cp.sum(w) == 1,\n",
    "        f == B @ (w - wb),\n",
    "        w >= 0,\n",
    "        port_risk <= (tev ** 2) / 12\n",
    "    ]\n",
    "\n",
    "    prob = cp.Problem(cp.Maximize(port_return), constraints)\n",
    "    prob.solve(verbose=False, solver=cp.CLARABEL)\n",
    "    collect_wt[(tev, dt)] = pd.Series((W @ w.value).flatten(), index=tradable_ids)\n",
    "    collect_indu_wt[(tev, dt)] = pd.Series(w.value.flatten(), index=indu_labels)\n",
    "\n",
    "wts = pd.DataFrame.from_dict(collect_wt, orient='index').fillna(0)\n",
    "wts.index.names = ['tev', 'date']\n",
    "\n",
    "collect_bt = {}\n",
    "for tev in cfg.tev_budget_iter:\n",
    "    wt = wts.xs(tev)\n",
    "    collect_bt[tev] = wt.shift(1).mul(rt).dropna(how='all').sum(axis=1)\n",
    "\n",
    "# Backtests\n",
    "bt = pd.DataFrame.from_dict(collect_bt)\n",
    "bt.columns = [f'TEV: {x}' for x in bt.columns]\n",
    "\n",
    "# Benchmark\n",
    "bm_wt = pd.DataFrame.from_dict(collect_bm, orient='index')\n",
    "bm_rt = bm_wt.shift(1).mul(rt.reindex(bm_wt.columns, axis=1)).dropna(how='all').sum(axis=1)\n",
    "\n",
    "df = bm_rt.to_frame(name='Benchmark').join(bt).add(1).cumprod()\n",
    "df = df.div(df.iloc[0])\n",
    "df.apply(np.log).plot()\n",
    "df.plot()\n",
    "\n",
    "tracking = df.pct_change().sub(df['Benchmark'].pct_change(), axis=0).drop('Benchmark', axis=1)\n",
    "ir = tracking.mean().div(tracking.std()).mul(np.sqrt(12))\n",
    "sr = df.pct_change().mean().div(df.pct_change().std()).mul(np.sqrt(12))\n",
    "display(ir.sort_values())\n",
    "display(sr.sort_values())\n",
    "display(tracking.std().mul(np.sqrt(12)).sort_values())\n",
    "\n",
    "zero_flags = np.isclose(bm_wt, 0, atol=1e-8)\n",
    "total = bm_wt.mask(zero_flags).count(axis=1)\n",
    "zero_flags = np.isclose(wts, 0, atol=1e-8)\n",
    "print('Avrage number of stocks', wts.mask(zero_flags).count(axis=1).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
