{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hmmlearn.hmm import GaussianHMM\n",
    "import cvxpy as cvx\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "from regimeaware.core.opt import min_EVaR_portfolio\n",
    "\n",
    "n_iterations = 100\n",
    "n_stocks = 100\n",
    "n_states = 3\n",
    "trn_periods = 600\n",
    "test_periods = 120  # Length of OOS period\n",
    "alpha = 0.05  # confidence level for VaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The random return generation should be done once, and then use subsets of it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fctr_rt = pd.read_pickle(fr\"{os.path.abspath(os.path.join(os.getcwd(), '..'))}\\ff.pkl\").drop([\"rf\", \"umd\"], axis=1)\n",
    "loadings_cov = pd.read_pickle(fr\"{os.path.abspath(os.path.join(os.getcwd(), '..'))}\\loadings_cov.pkl\")\n",
    "loadings_means = pd.read_pickle(fr\"{os.path.abspath(os.path.join(os.getcwd(), '..'))}\\loadings_means.pkl\")\n",
    "mcap = pd.read_pickle(fr\"{os.path.abspath(os.path.join(os.getcwd(), '..'))}\\mcap.pkl\")\n",
    "sec_rt = pd.read_pickle(fr\"{os.path.abspath(os.path.join(os.getcwd(), '..'))}\\sec_rt.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianHMM(implementation=&#x27;scaling&#x27;, n_components=3, random_state=123)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianHMM</label><div class=\"sk-toggleable__content\"><pre>GaussianHMM(implementation=&#x27;scaling&#x27;, n_components=3, random_state=123)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianHMM(implementation='scaling', n_components=3, random_state=123)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training sample\n",
    "trn = fctr_rt.copy()\n",
    "\n",
    "gen_hmm = GaussianHMM(\n",
    "    n_components=n_states,\n",
    "    covariance_type=\"diag\",\n",
    "    random_state=123,\n",
    "    min_covar=1E-3,\n",
    "    tol=1E-2,\n",
    "    implementation=\"scaling\"\n",
    ")\n",
    "\n",
    "gen_hmm.fit(trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e078412626144924b708f370841b425c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# TODO: Will also loop over these two eventually\n",
    "\n",
    "\n",
    "# Seeds\n",
    "gen_hmm.random_state = 123\n",
    "np.random.seed(123)\n",
    "\n",
    "port_rwls = {}\n",
    "port_ols = {}\n",
    "\n",
    "for iter in tqdm(range(n_iterations)):\n",
    "    # --------------------------------------------\n",
    "    # Factor returns\n",
    "    X, Z = gen_hmm.sample(trn_periods + test_periods)\n",
    "    G = gen_hmm.predict_proba(X)\n",
    "    R = np.zeros((trn_periods + test_periods, n_stocks))\n",
    "\n",
    "    # True factor loadings\n",
    "    _vals = np.random.multivariate_normal(mean=loadings_means, cov=loadings_cov, size=n_stocks)\n",
    "    B = pd.DataFrame(_vals, columns=loadings_means.index).T\n",
    "    B.columns.name = \"stock\"\n",
    "    B.index.names = [\"factor\", \"state\"]\n",
    "    B = B.stack()\n",
    "\n",
    "    # Stock returns\n",
    "    E = np.random.normal(loc=0, scale=np.sqrt(.0025), size=R.shape)\n",
    "    for _t, s_t in enumerate(Z):\n",
    "        x_t = pd.Series(X[_t], fctr_rt.columns)\n",
    "        x_t.index.name = \"factor\"\n",
    "        R[_t] += B.xs(s_t, level=\"state\").mul(x_t).groupby(\"stock\").sum()\n",
    "    R += E\n",
    "\n",
    "    # --------------------------------------------\n",
    "    # Iterative backtest\n",
    "    W_rwls = np.zeros((test_periods, n_stocks))\n",
    "    W_ols = np.zeros((test_periods, n_stocks))\n",
    "\n",
    "    for t in range(test_periods):\n",
    "        # HMM fitting\n",
    "        fctr_t = X[:trn_periods + t]\n",
    "        hmm_t = GaussianHMM(\n",
    "            n_components=n_states,\n",
    "            covariance_type=\"diag\",\n",
    "            random_state=123,\n",
    "            min_covar=1E-3,\n",
    "            tol=1E-2,\n",
    "            implementation=\"scaling\"\n",
    "        )\n",
    "\n",
    "        hmm_t.fit(fctr_t)\n",
    "\n",
    "        # Factor regime-dependent parameters\n",
    "        mu_f = hmm_t.means_\n",
    "        Sigma_f = hmm_t.covars_\n",
    "        G_hat = hmm_t.predict_proba(fctr_t)\n",
    "\n",
    "        _x = sm.add_constant(fctr_t)  # Exog\n",
    "\n",
    "        V_t = {}\n",
    "        R_t = {}\n",
    "\n",
    "        for s in range(n_states):\n",
    "            _g = G_hat[:trn_periods + t, s]  # Posterior probabilities\n",
    "            pi_t = G_hat[trn_periods + t - 1]\n",
    "\n",
    "            B_s = np.empty(shape=(n_stocks, X.shape[1] + 1))\n",
    "            E_s = np.zeros(shape=(n_stocks, n_stocks))\n",
    "\n",
    "            for i in range(n_stocks):\n",
    "                _y = R[:trn_periods + t, i]  # Endog\n",
    "\n",
    "                # Regimes-weighted least squares\n",
    "                mdl = sm.WLS(_y, _x, weights=_g, hasconst=True).fit()\n",
    "            \n",
    "                B_s[i] = mdl.params\n",
    "                E_s[i, i] = np.var(mdl.resid)\n",
    "\n",
    "            V_st = B_s[:, 1:] @ Sigma_f[s] @ B_s[:, 1:].T + E_s  # Stock-level covariance matrix\n",
    "            V_t[s] = V_st + V_st.conj().T / 2  # Make sure it is a Hermitian symmetric matrix.\n",
    "            R_t[s] = (B_s @ np.concatenate([np.array([1]), mu_f[s]]).reshape(-1, 1)).flatten()  # Stock-level returns vector\n",
    "\n",
    "        # Single-regime benchmark\n",
    "        B_hat = np.empty(shape=(n_stocks, X.shape[1] + 1))\n",
    "        E_hat = np.zeros(shape=(n_stocks, n_stocks))\n",
    "\n",
    "        mu_hat = np.mean(_x, axis=0)\n",
    "        Sigma_hat = np.cov(_x, rowvar=False)\n",
    "\n",
    "        for i in range(n_stocks):\n",
    "            _y = R[:trn_periods + t, i]  # Endog\n",
    "            mdl_ols = sm.OLS(endog=_y, exog=_x, hasconst=True).fit()\n",
    "\n",
    "            B_hat[i] = mdl_ols.params\n",
    "            E_hat[i, i] = np.var(mdl_ols.resid)\n",
    "\n",
    "        V_hat_t = B_hat @ Sigma_hat @ B_hat.T + E_hat  # Stock-level covariance matrix\n",
    "        V_hat_t = V_hat_t + V_hat_t.conj().T / 2  # Make sure it is a Hermitian symmetric matrix.\n",
    "        R_hat_t = (B_hat @ mu_hat.reshape(-1, 1)).flatten()  # Stock-level returns vector\n",
    "\n",
    "        # Portfolio optimization\n",
    "        w_rwls, _, _ = min_EVaR_portfolio(alpha=alpha, L=2, mus=R_t, sigmas=V_t, pi=pi_t)\n",
    "        w_hat, _, _ = min_EVaR_portfolio(alpha=alpha, L=2, mus=[R_hat_t], sigmas=[V_hat_t], pi=[1])\n",
    "\n",
    "        W_rwls[t, :] = w_rwls\n",
    "        W_ols[t, :] = w_hat\n",
    "\n",
    "    port_ols[(alpha, iter)] = pd.DataFrame(W_ols)\n",
    "    port_rwls[(alpha, iter)] = pd.DataFrame(W_rwls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.21370968070579122,\n",
       " 0.04034219892937707,\n",
       " 0.10466790625079736,\n",
       " 0.017241856417012702,\n",
       " 0.28102498093717854,\n",
       " 0.29648015785394066,\n",
       " 0.0036053754332561194,\n",
       " 0.16489854606201493,\n",
       " 0.1148216984075856,\n",
       " 0.008499602174763643]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_test = pd.DataFrame(R[trn_periods:])\n",
    "x = 0\n",
    "\n",
    "\n",
    "[R_test.shift(-1).mul(port_rwls[x]).sum(axis=1).add(1).prod() - 1 for x in range(n_iterations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2528699789644484,\n",
       " 0.0485712839856105,\n",
       " 0.14949587423750876,\n",
       " -0.0037905200505866654,\n",
       " 0.2297829183360791,\n",
       " 0.27919179748592926,\n",
       " -0.024672967259734335,\n",
       " 0.1730383365813304,\n",
       " 0.12375855205141617,\n",
       " -0.0011427141444446676]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[R_test.shift(-1).mul(port_ols[x]).sum(axis=1).add(1).prod() - 1 for x in range(n_iterations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\franc\\miniconda3\\envs\\research\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn import preprocessing\n",
    "from scipy.stats.mstats import winsorize\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from regimeaware.routines import cfg\n",
    "from datetime import datetime\n",
    "from regimeaware.core.methodologies import RegimeWeightedLS\n",
    "from tqdm import tqdm\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import cvxpy as cvx\n",
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "dt = datetime(2023, 12, 31)\n",
    "\n",
    "# cfg.data_fldr = r\"C:\\Users\\franc\\My Drive\\bin\\regimeaware\\data\"\n",
    "\n",
    "n_stocks = 5000\n",
    "n_states = 3\n",
    "n_periods = 600\n",
    "\n",
    "ff = pd.read_pickle(f'{cfg.data_fldr}/ff.pkl').loc[:dt, cfg.factor_set]\n",
    "crsp = pd.read_pickle(f'{cfg.data_fldr}/crsp.pkl')\n",
    "rt = pd.pivot_table(crsp[['excess_ret']], index='date', columns='permno', values='excess_ret')\n",
    "mcap = crsp['shrout'].mul(crsp['prc'].abs()).xs(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Number of states\n",
    "\n",
    "\\begin{aligned}\n",
    "-\\frac{n}{2}\\log SSR\n",
    "                  -\\frac{n}{2}\\left(1+\\log\\left(\\frac{2\\pi}{n}\\right)\\right)\n",
    "                  -\\frac{1}{2}\\log\\left(\\left|W\\right|\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "\\begin{aligned}\n",
    "BIC = k \\log \\left( n \\right) - 2 \\log \\left( \\hat{L} \\right)\n",
    "\\end{aligned}\n",
    "\n",
    "BIC = -2*logLike + num_free_params * log(num_of_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parameter recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcap_sorted = mcap.sort_values(ascending=False)\n",
    "mcap_coverage = mcap_sorted.cumsum().div(mcap.sum())\n",
    "mcap_flags = mcap_coverage < .999\n",
    "size_ids = mcap_flags[mcap_flags].index\n",
    "active_ids = rt.reindex(size_ids, axis=1).iloc[-1].dropna().index\n",
    "n_obs = rt[active_ids].count()\n",
    "sample_ids = n_obs[n_obs > 300].index\n",
    "print(f'Number of active stocks: {len(sample_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 HMM fitting on real factor returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training sample\n",
    "trn = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()  \n",
    "# trn_raw = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()\n",
    "# scaler = preprocessing.StandardScaler(copy=True).fit(trn_raw)\n",
    "# trn = scaler.transform(trn_raw)\n",
    "# trn = pd.DataFrame(trn, index=trn_raw.index, columns=trn_raw.columns)\n",
    "\n",
    "hmm = GaussianHMM(\n",
    "    n_components=n_states,\n",
    "    covariance_type=\"diag\",\n",
    "    random_state=cfg.hm_rs,\n",
    "    min_covar=cfg.hm_min_covar,\n",
    "    tol=cfg.hm_tol,\n",
    "    implementation=cfg.hm_implementation\n",
    ")\n",
    "hmm.fit(trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Fit RWLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sec_rt = rt.loc[cfg.trn_start_dt:dt, sample_ids].copy()  # Stock excess returns\n",
    "hmm_probs = pd.DataFrame(hmm.predict_proba(trn), index=trn.index)\n",
    "\n",
    "collect_loadings = {}\n",
    "collect_resid = {}\n",
    "\n",
    "for sec_id in tqdm(sec_rt.columns):\n",
    "    _y = sec_rt[sec_id].dropna()\n",
    "    _y = _y - _y.mean()\n",
    "    _x = trn.reindex(_y.index)\n",
    "    _x = _x - _x.mean()\n",
    "    _g = hmm_probs.reindex(_y.index)\n",
    "    \n",
    "    for s in range(n_states):\n",
    "        mdl = sm.WLS(_y, _x, weights=_g[s], hasconst=False)\n",
    "        collect_loadings[(sec_id, s)] = mdl.fit().params\n",
    "        collect_resid[(sec_id, s)] = mdl.fit().resid.var(ddof=0)\n",
    "\n",
    "B = pd.DataFrame.from_dict(collect_loadings, orient='index')\n",
    "B.index.names = [\"permno\", \"state\"]\n",
    "v = pd.Series(collect_resid)\n",
    "v.index.names = [\"permno\", \"state\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_loadings = B.melt(ignore_index=False).reset_index().pivot_table(index=\"permno\", columns=[\"variable\", \"state\"], values=\"value\")\n",
    "_loadings = _loadings[[(x, y) for x in cfg.factor_set for y in range(n_states)]]\n",
    "\n",
    "# sw = DescrStatsW(_loadings, weights=mcap.reindex(_loadings.index).fillna(0))\n",
    "# _loadings_mean = pd.Series(sw.mean, index=_loadings.columns)\n",
    "# _loadings_cov = pd.DataFrame(sw.cov, index=_loadings.columns, columns=_loadings.columns)\n",
    "\n",
    "_loadings_cov = _loadings.cov()\n",
    "_loadings_mean = _loadings.mean()\n",
    "\n",
    "# Block-diagonal covariance matrix\n",
    "_loadings_cov_diag = pd.DataFrame(index=_loadings_cov.index, columns=_loadings_cov.columns, dtype=float)\n",
    "for fctr in cfg.factor_set:\n",
    "    _loadings_cov_diag.loc[fctr, fctr] = _loadings_cov.loc[fctr, fctr].values\n",
    "\n",
    "_loadings_cov = _loadings_cov_diag.fillna(0)\n",
    "\n",
    "# True loadings simulation\n",
    "np.random.seed(cfg.hm_rs)\n",
    "_vals = np.random.multivariate_normal(mean=_loadings_mean, cov=_loadings_cov, size=n_stocks)\n",
    "\n",
    "true_loadings = pd.DataFrame(_vals, columns=_loadings.columns).T\n",
    "true_loadings.columns.name = \"stock\"\n",
    "true_loadings.index.names = [\"factor\", \"state\"]\n",
    "true_loadings = true_loadings.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated stock returns\n",
    "X, Z = hmm.sample(n_periods)\n",
    "G = hmm.predict_proba(X)\n",
    "R = np.zeros((n_periods, n_stocks))\n",
    "\n",
    "np.random.seed(cfg.hm_rs)\n",
    "E = np.random.normal(loc=0, scale=np.sqrt(.0025), size=R.shape)\n",
    "\n",
    "for t, s_t in enumerate(Z):\n",
    "    x_t = pd.Series(X[t], cfg.factor_set)\n",
    "    x_t.index.name = \"factor\"\n",
    "    R[t] += true_loadings.xs(s_t, level=\"state\").mul(x_t).groupby(\"stock\").sum()\n",
    "\n",
    "R += E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_params = {}\n",
    "for i in range(n_stocks):\n",
    "    y = R[:, i]\n",
    "    for s in range(n_states):\n",
    "        mdl = sm.WLS(y, sm.add_constant(pd.DataFrame(X, columns=cfg.factor_set)), weights=G[:, s])\n",
    "        # TODO: using the actual posterior probs for now until we nail down the issue\n",
    "        collect_params[(s, i)] = mdl.fit().params\n",
    "\n",
    "est_loadings = pd.DataFrame.from_dict(collect_params)\n",
    "est_loadings.columns.names = ['state', 'stock']\n",
    "est_loadings.index.name = 'factor'\n",
    "est_loadings = est_loadings.melt(ignore_index=False).reset_index().set_index(['stock', 'state', 'factor']).squeeze()\n",
    "est_loadings.name = 'estimated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadings = true_loadings.to_frame(\"True\").join(est_loadings.to_frame(\"Estimated\"))\n",
    "loadings[\"delta\"] = loadings[\"Estimated\"] - loadings[\"True\"]\n",
    "loadings = loadings.join(true_loadings.groupby([\"factor\", \"state\"]).std().to_frame(\"sigma\"))\n",
    "loadings[\"std_delta\"] = loadings[\"delta\"] / loadings[\"sigma\"]\n",
    "loadings[\"abs_delta\"] = loadings[\"delta\"].abs()\n",
    "\n",
    "for fctr in cfg.factor_set:\n",
    "    data = loadings.xs(fctr).reset_index()\n",
    "    g = sns.jointplot(data, x=\"True\", y=\"Estimated\", hue=\"state\", palette=\"Set2\", height=4, ratio=5, space=0, marginal_kws=dict(bw_adjust=2))\n",
    "    g.ax_joint.grid(ls='--', alpha=.5, zorder=-25)\n",
    "    g.ax_joint.tick_params(left=False, bottom=False)\n",
    "    g.ax_marg_x.tick_params(left=False, bottom=False)\n",
    "    g.ax_marg_y.tick_params(left=False, bottom=False)\n",
    "    # g.ax_joint.set_xlabel(f\"$\\lambda_{fctr}$\")\n",
    "    # g.ax_joint.set_ylabel(f\"$\\hat{{\\lambda}}_{{fctr}}$\")\n",
    "    # g.ax_joint.set_ylim(g.ax_joint.get_xlim())\n",
    "    # g.ax_joint.set_yticks(g.ax_joint.get_xticks())\n",
    "    # ax.set_yticklabels(ax.get_xticklabels())\n",
    "    # fig = plt.gcf()\n",
    "    # fig.suptitle(fctr)\n",
    "    # plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Portfolio simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K(w):\n",
    "    u = cvx.vstack([cvx.log(pi[i])\n",
    "      - gamma * mus[i] @ w\n",
    "      + (gamma**2/2) * cvx.quad_form(w, Sigmas[i]) for i in range(k)])\n",
    "    return cvx.log_sum_exp(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = cvx.Variable(n)\n",
    "objective = cvx.Minimize(K(w))\n",
    "constraints = [ w >= 0, cvx.sum(w) == 1 ]\n",
    "egm_prob = cvx.Problem(objective, constraints)\n",
    "egm_prob.solve(solver=cvx.MOSEK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# -----------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIC = -2*logLike + num_free_params * log(num_of_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "\n",
    "Y = rt.loc[cfg.trn_start_dt:dt, sample_ids].copy()\n",
    "X = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()\n",
    "\n",
    "mdl = GaussianHMM(\n",
    "    n_components=n,\n",
    "    covariance_type=\"diag\",\n",
    "    random_state=cfg.hm_rs,\n",
    "    min_covar=cfg.hm_min_covar,\n",
    "    tol=cfg.hm_tol,\n",
    "    implementation=cfg.hm_implementation\n",
    ")\n",
    "mdl.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "-\\frac{n}{2}\\log SSR\n",
    "                  -\\frac{n}{2}\\left(1+\\log\\left(\\frac{2\\pi}{n}\\right)\\right)\n",
    "                  -\\frac{1}{2}\\log\\left(\\left|W\\right|\\right)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2\n",
    "\n",
    "Y = rt.loc[cfg.trn_start_dt:dt, sample_ids].copy()\n",
    "X = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()\n",
    "\n",
    "mdl = GaussianHMM(\n",
    "    n_components=n,\n",
    "    covariance_type=\"diag\",\n",
    "    random_state=cfg.hm_rs,\n",
    "    min_covar=cfg.hm_min_covar,\n",
    "    tol=cfg.hm_tol,\n",
    "    implementation=cfg.hm_implementation\n",
    ")\n",
    "mdl.fit(X)\n",
    "\n",
    "\n",
    "g = pd.DataFrame(mdl.predict_proba(X), index=ff.index, columns=range(n))\n",
    "\n",
    "collect_betas = {}\n",
    "collect_resid = {}\n",
    "\n",
    "for sec_id in tqdm(Y.columns):\n",
    "    y = Y[sec_id].dropna()\n",
    "    rwls = RegimeWeightedLS(endog=y, exog=X, emission_prob=g)\n",
    "    rwls.fit(add_constant=True)\n",
    "\n",
    "    collect_betas[sec_id] = rwls.params.stack()\n",
    "    collect_resid[sec_id] = rwls.resid.var(ddof=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{aligned}\n",
    "BIC = k \\log \\left( n \\right) - 2 \\log \\left( \\hat{L} \\right)\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "I'm adding up the BIC for now, but there is an issue with the number of observations. The loglikelihood\n",
    "of stocks with longer time series will be higher, so the BIC will be lower. I need to adjust for that.\n",
    "I also need to adjust for the number of regimes (and total number of parameters) in the model.\n",
    "\"\"\"\n",
    "collect_mdl_llf = {}\n",
    "collect_mdl_bic = {}\n",
    "\n",
    "for n_states in range(1, 3):\n",
    "    Y = rt.loc[cfg.trn_start_dt:dt, sample_ids].copy()\n",
    "    X = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()\n",
    "\n",
    "    hmm = GaussianHMM(\n",
    "        n_components=n_states,\n",
    "        covariance_type=\"diag\",\n",
    "        random_state=cfg.hm_rs,\n",
    "        min_covar=cfg.hm_min_covar,\n",
    "        tol=cfg.hm_tol,\n",
    "        implementation=cfg.hm_implementation\n",
    "    )\n",
    "    hmm.fit(X)\n",
    "\n",
    "\n",
    "    g = pd.DataFrame(hmm.predict_proba(X), index=ff.index, columns=range(n_states))\n",
    "\n",
    "    collect_llf = {}\n",
    "    collect_bic = {}\n",
    "\n",
    "    for sec_id in tqdm(Y.columns, desc=f\"{n_states} states\"):\n",
    "        y = Y[sec_id].dropna()\n",
    "\n",
    "        _llf = 0\n",
    "        _bic = 0\n",
    "        for s in range(n_states):\n",
    "            w = g[s].reindex(y.index)\n",
    "            mdl = sm.WLS(y, sm.add_constant(X.reindex(y.index)), weights=w)\n",
    "            _llf += mdl.fit().llf\n",
    "            _bic += mdl.fit().bic\n",
    "\n",
    "        collect_llf[sec_id] = _llf\n",
    "        collect_bic[sec_id] = _bic\n",
    "\n",
    "    collect_mdl_llf[n_states] = pd.Series(collect_llf)\n",
    "    collect_mdl_bic[n_states] = pd.Series(collect_bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm._get_n_fit_scalars_per_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = sum(hmm._get_n_fit_scalars_per_param().values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nobs2 = self.nobs / 2.0\n",
    "# SSR = np.sum((self.wendog - np.dot(self.wexog, params))**2, axis=0)\n",
    "# llf = -np.log(SSR) * nobs2      # concentrated likelihood\n",
    "# llf -= (1+np.log(np.pi/nobs2))*nobs2  # with constant\n",
    "# llf += 0.5 * np.sum(np.log(self.weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "ssr = np.sum(rwls.resid[s] ** 2)\n",
    "n = len(y)\n",
    "w = g[s].reindex(y.index)\n",
    "\n",
    "-n / 2 * np.log(ssr) - n / 2 * (1 + np.log(2 * np.pi / n)) + 1 /2 * np.sum(np.log(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = sm.WLS(y, sm.add_constant(X.reindex(y.index)), weights=w)\n",
    "mdl.fit().llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit(cov_type=\"HAC\", cov_kwds={'maxlags': 12}).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.fit().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 3\n",
    "\n",
    "Y = rt.loc[cfg.trn_start_dt:dt, sample_ids].copy()\n",
    "X = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()\n",
    "\n",
    "mdl = GaussianHMM(\n",
    "    n_components=n,\n",
    "    covariance_type=\"diag\",\n",
    "    random_state=cfg.hm_rs,\n",
    "    min_covar=cfg.hm_min_covar,\n",
    "    tol=cfg.hm_tol,\n",
    "    implementation=cfg.hm_implementation\n",
    ")\n",
    "mdl.fit(X)\n",
    "\n",
    "\n",
    "g = pd.DataFrame(mdl.predict_proba(X), index=ff.index, columns=range(n))\n",
    "\n",
    "collect_betas = {}\n",
    "collect_resid = {}\n",
    "\n",
    "for sec_id in tqdm(Y.columns):\n",
    "    y = Y[sec_id].dropna()\n",
    "    mdl = RegimeWeightedLS(endog=y, exog=X, emission_prob=g)\n",
    "    mdl.fit(add_constant=True)\n",
    "\n",
    "    collect_betas[sec_id] = mdl.params.stack()\n",
    "    collect_resid[sec_id] = mdl.resid.var(ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(collect_resid).T.stack().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(collect_resid).T.stack().plot.hist(bins=50, alpha=.5, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "stats.chi2.fit(pd.DataFrame.from_dict(collect_resid).T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(np.random.chisquare(1, 30000)).plot.hist(bins=50, alpha=.5, density=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = pd.DataFrame.from_dict(collect_betas).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(B[\"mktrf\"].max(axis=1) - B[\"mktrf\"].min(axis=1)).plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = (B[\"mktrf\"].max(axis=1) - B[\"mktrf\"].min(axis=1))\n",
    "n_obs = rt.count()[aa.index]\n",
    "size = crsp[\"mktcap\"].xs('2023-12-31').reindex(aa.index).fillna(0)\n",
    "size = size.rank(pct=True)\n",
    "df = aa.to_frame(\"delta\").join(n_obs.to_frame(\"n_obs\")).join(size.to_frame(\"size\"))\n",
    "df.sort_values(\"delta\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.scatter(x=\"n_obs\", y=\"delta\", c=\"size\", cmap=\"coolwarm_r\", alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the biggest factor loading deltas usually take place in short time series\n",
    "- the same can be said with small stocks\n",
    "- weighting by mcap should alleviate some of this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(B[\"mktrf\"].max(axis=1) - B[\"mktrf\"].min(axis=1)).sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[\"mktrf\"].xs(78170)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt[78170].dropna().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(mean=B[\"mktrf\"].mean(), cov=B[\"mktrf\"].cov(), size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "labels = B.drop(\"const\", axis=1).columns\n",
    "sw = DescrStatsW(B[labels], weights=crsp[\"mktcap\"].xs('2023-12-31').reindex(B.index).fillna(0))\n",
    "display(pd.DataFrame(sw.cov, index=labels, columns=labels))\n",
    "display(pd.Series(sw.mean, index=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(np.linalg.inv(np.diag(sw.std)) @ sw.cov @ np.linalg.inv(np.diag(sw.std)), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "\n",
    "loadings_dist = {}\n",
    "\n",
    "for fctr in [\"mktrf\", \"smb\", \"hml\", \"rmw\", \"cma\"]:\n",
    "    _dist = {}\n",
    "    sw = DescrStatsW(B[fctr], weights=crsp[\"mktcap\"].xs('2023-12-31').reindex(B[fctr].index).fillna(0))\n",
    "    _dist[\"mu\"] = sw.mean\n",
    "    _dist[\"cov\"] = sw.cov\n",
    "    loadings_dist[fctr] = _dist\n",
    "\n",
    "loadings_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(np.diag(sw.std)) @ sw.cov @ np.linalg.inv(np.diag(sw.std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[\"mktrf\"].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[\"mktrf\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(mean=sw.mean, cov=sw.cov, size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B[\"mktrf\"].cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl.covars_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recovery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states_to_try = range(1, 9)\n",
    "\n",
    "bic = pd.Series(index=states_to_try, dtype=float)\n",
    "aic = pd.Series(index=states_to_try, dtype=float)\n",
    "\n",
    "# trn_raw = ff.copy()\n",
    "# scaler = preprocessing.StandardScaler(copy=True).fit(trn_raw)\n",
    "# trn = scaler.transform(trn_raw)\n",
    "trn = ff.copy()\n",
    "\n",
    "collect_mdls = {}\n",
    "\n",
    "for n in states_to_try:\n",
    "    mdl = GaussianHMM(\n",
    "        n_components=n,\n",
    "        covariance_type=\"diag\",\n",
    "        random_state=999,\n",
    "        min_covar=cfg.hm_min_covar,\n",
    "        tol=cfg.hm_tol,\n",
    "        implementation=cfg.hm_implementation\n",
    "    )\n",
    "    mdl.fit(trn)\n",
    "    _score = mdl.bic(trn)\n",
    "    collect_mdls[_score] = mdl\n",
    "    bic[n] = _score\n",
    "    aic[n] = mdl.aic(trn)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 3.25))\n",
    "plot_map = {'AIC': (aic, '--', 1.25, 'o'), 'BIC': (bic, '-', 1.75, 's')}\n",
    "\n",
    "for label, params in plot_map.items():\n",
    "    ax.plot(params[0], color='k', marker=params[3], mfc='white', lw=params[2], ls=params[1])\n",
    "    ax.grid(ls='--', alpha=.75)\n",
    "\n",
    "# ax.set_title('Information Criterion', weight='bold')\n",
    "ax.set_ylabel('Information Criterion')\n",
    "ax.set_xlabel('Number of Market Regimes')\n",
    "ax.legend(['AIC', 'BIC'])\n",
    "ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "ax.tick_params(axis='both', bottom=False, left=False)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = collect_mdls[min(collect_mdls)]\n",
    "n_states = mdl.n_components\n",
    "print(f'Number of states: {n_states}')\n",
    "\n",
    "hm_mu = mdl.means_\n",
    "hm_sigma = mdl.covars_\n",
    "hm_transmat = mdl.transmat_\n",
    "hm_start_p = mdl.startprob_\n",
    "hm_post_p = mdl.predict_proba(X=trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_var = pd.Series(index=pd.MultiIndex.from_tuples([(dt, x) for x in sample_ids], names=['date', 'id']))\n",
    "\n",
    "Y = rt.loc[cfg.trn_start_dt:dt, sample_ids].copy()\n",
    "X = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()\n",
    "g = pd.DataFrame(hm_post_p, index=ff.index, columns=range(n_states))\n",
    "B = pd.DataFrame(index=ff.index, columns=ff.columns)\n",
    "\n",
    "collect_betas = {}\n",
    "collect_resid = {}\n",
    "\n",
    "for sec_id in tqdm(Y.columns):\n",
    "    y = Y[sec_id].dropna()\n",
    "    mdl = RegimeWeightedLS(endog=y, exog=X, emission_prob=g)\n",
    "    mdl.fit(add_constant=True)\n",
    "\n",
    "    collect_betas[sec_id] = mdl.params.stack()\n",
    "    collect_resid[sec_id] = mdl.resid.var(ddof=0)\n",
    "\n",
    "\n",
    "state_betas = pd.DataFrame.from_dict(collect_betas)\n",
    "state_betas.index.names = ['param', 'state']\n",
    "state_var = pd.DataFrame(collect_resid)\n",
    "state_var.index.name = \"state\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = rt.loc[cfg.trn_start_dt:dt, sample_ids].copy()\n",
    "X = ff.loc[cfg.trn_start_dt:dt, cfg.factor_set].copy()\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "collect_betas = {}\n",
    "collect_var = {}\n",
    "\n",
    "for sec_id in tqdm(Y.columns):\n",
    "    y = Y[sec_id]\n",
    "    cmn_idx = X.join(y).dropna().index\n",
    "    mdl = sm.OLS(y.reindex(cmn_idx), X.reindex(cmn_idx))\n",
    "    mdl_fit = mdl.fit()\n",
    "\n",
    "    collect_betas[sec_id] = mdl_fit.params.copy()\n",
    "    collect_var[sec_id] = mdl_fit.mse_resid\n",
    "\n",
    "ols_var = pd.Series(collect_var)\n",
    "ols_betas = pd.DataFrame(collect_betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical distribution of factor loadings\n",
    "fig, axs = plt.subplots(nrows=len(cfg.factor_set), ncols=1, figsize=(3.75, len(cfg.factor_set) * 1.5), sharex=True, sharey=True)\n",
    "for i, fact in enumerate(cfg.factor_set):\n",
    "    _vals = ols_betas.xs(fact).to_frame().join(mcap.to_frame('mcap'))\n",
    "    _vals[fact] = winsorize(_vals[fact], limits=[.01, .01]).data\n",
    "    \n",
    "    _mu = _vals[fact].mean()\n",
    "    _sigma = _vals[fact].std()\n",
    "    \n",
    "    ax = axs.flatten()[i]\n",
    "    ax.text(.95, .95, f'Mean: {_mu:.2f}\\nStd: {_sigma:.2f}', ha='right', va='top', transform=ax.transAxes)\n",
    "    sns.kdeplot(data=_vals, x=fact, ax=ax, bw_adjust=2, fill=True, zorder=25, weights='mcap')\n",
    "    ax.set_title(fact, weight='bold')\n",
    "    ax.grid(ls='--', alpha=.5, zorder=-25)\n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_xlim(-3.5, 3.5)\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical distribution of factor loadings\n",
    "fig, axs = plt.subplots(nrows=len(cfg.factor_set), ncols=1, figsize=(5, len(cfg.factor_set) * 2), sharex='row', sharey='row')\n",
    "collect_params = {}\n",
    "for i, fact in enumerate(cfg.factor_set):\n",
    "    ax = axs[i]\n",
    "    for m in range(n_states):\n",
    "        _vals = state_betas.xs(fact).xs(m).to_frame(fact).join(mcap.to_frame('mcap'))\n",
    "        _vals[fact] = winsorize(_vals[fact], limits=[.01, .01]).data\n",
    "        sns.kdeplot(data=_vals, x=fact, ax=ax, bw_adjust=1.5, fill=False, zorder=25, weights='mcap')\n",
    "        collect_params[(fact, m)] = (_vals[fact].mean(), _vals[fact].std())\n",
    "\n",
    "    ax.legend([f\"State {x}\" for x in range(n_states)], loc='upper right')\n",
    "    ax.set_title(f\"{fact} ({m})\", weight='bold')\n",
    "    ax.axvline(np.mean(_vals), c='firebrick')\n",
    "    ax.grid(ls='--', alpha=.5, zorder=-25)\n",
    "    ax.set_xlim(-4, 4)\n",
    "    ax.tick_params(axis='both', which='both', length=0)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_mu = mdl.means_\n",
    "hm_sigma = mdl.covars_\n",
    "hm_transmat = mdl.transmat_\n",
    "hm_start_p = mdl.startprob_\n",
    "hm_post_p = mdl.predict_proba(X=trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = GaussianHMM(\n",
    "    n_components=n_states,\n",
    "    covariance_type=\"diag\",\n",
    "    random_state=999,\n",
    "    min_covar=cfg.hm_min_covar,\n",
    "    tol=cfg.hm_tol,\n",
    "    implementation=cfg.hm_implementation\n",
    ")\n",
    "mdl.means_ = hm_mu\n",
    "mdl.transmat_ = hm_transmat\n",
    "mdl.startprob_ = hm_start_p\n",
    "mdl.means_ = hm_mu\n",
    "mdl.fit(ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO:\n",
    "The point of using the historical data should be \n",
    "\n",
    "1. Have an idea of how many regimes are there taking the 5-factor model (3 states?)\n",
    "1. Given these m-states, what are the distributions of these factors, are they statistically different?\n",
    "1. What are the state-dependent parameters of these distributions? (to be used in the simulations)\n",
    "1. Given these m-states simulate long paths for the hidden states\n",
    "1. Simulate synthetic returns for n stocks, drawing the betas from the corresponding distributions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startprob = np.array([0.6, 0.3, 0.1, 0.0])\n",
    "transmat = np.array(\n",
    "    [\n",
    "        [0.7, 0.2, 0.0, 0.1],\n",
    "        [0.3, 0.5, 0.2, 0.0],\n",
    "        [0.0, 0.3, 0.5, 0.2],\n",
    "        [0.2, 0.0, 0.2, 0.6]\n",
    "    ]\n",
    ")\n",
    "\n",
    "means = np.array(\n",
    "    [\n",
    "        [0.0, 0.0],\n",
    "        [0.0, 11.0],\n",
    "        [9.0, 10.0],\n",
    "        [11.0, -1.0]\n",
    "    ]\n",
    ")\n",
    "\n",
    "covars = .5 * np.tile(np.identity(2), (4, 1, 1))\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "gen_model = hmm.GaussianHMM(n_components=4, covariance_type=\"full\")\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "gen_model.startprob_ = startprob\n",
    "gen_model.transmat_ = transmat\n",
    "gen_model.means_ = means\n",
    "gen_model.covars_ = covars\n",
    "\n",
    "# Generate samples\n",
    "X, Z = gen_model.sample(500)\n",
    "\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gen_model.predict_proba(X)).round(4)  # The probability of each state at each time point is pretty much either 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tile(np.identity(2), (2, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startprob = np.array([1, 0])\n",
    "transmat = np.array(\n",
    "    [\n",
    "        [0.85, 0.15],\n",
    "        [0.4, 0.6],\n",
    "    ]\n",
    ")\n",
    "\n",
    "means = np.array(\n",
    "    [\n",
    "        [0.1],\n",
    "        [-0.1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "covars = np.array([1, 1]).reshape(-1, 1)\n",
    "\n",
    "# Build an HMM instance and set parameters\n",
    "gen_model = hmm.GaussianHMM(n_components=2, covariance_type=\"diag\", random_state=12345)\n",
    "\n",
    "# Instead of fitting it from the data, we directly set the estimated\n",
    "# parameters, the means and covariance of the components\n",
    "gen_model.startprob_ = startprob\n",
    "gen_model.transmat_ = transmat\n",
    "gen_model.means_ = means\n",
    "gen_model.covars_ = covars\n",
    "\n",
    "# Generate samples\n",
    "X, Z = gen_model.sample(120)\n",
    "\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmat = np.array(\n",
    "    [\n",
    "        [0.85, 0.15],\n",
    "        [0.4, 0.6],\n",
    "    ]\n",
    ")\n",
    "np.linalg.matrix_power(transmat, 9999999).T @ np.array([1, 0]).reshape(-1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
